{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeeplabV3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import copy\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "from math import ceil\n",
    "from itertools import cycle\n",
    "from itertools import chain\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training start, 总共 80 epochs\n",
      "GPUs: cuda\n",
      "DeeplabV3+ with ResNet 101 backbone\n",
      "Current Labeled Example: 515\n",
      "Learning rate: other 0.01, and head is the SAME [world]\n",
      "Current batch: 16 [world]\n",
      "Current unsupervised loss function: semi_ce, with weight 1.5 and length 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "config json :\n",
      "name PS-MT(DeeplabV3+)\n",
      "experim_name TEST_warm\n",
      "n_labeled_examples 515\n",
      "ramp_up 12\n",
      "unsupervised_w 1.5\n",
      "lr_scheduler Poly\n",
      "gamma 0.5\n",
      "model {'supervised': False, 'semi': True, 'resnet': 101, 'sup_loss': 'DE', 'un_loss': 'semi_ce', 'epochs': 80, 'warm_up_epoch': 80, 'data_h_w': [224, 224]}\n",
      "optimizer {'type': 'SGD', 'args': {'lr': 0.01, 'weight_decay': 0.0001, 'momentum': 0.9}}\n",
      "train_supervised {'data_dir': 'FA', 'batch_size': 8, 'shuffle': True, 'crop_size': 224, 'split': 'train_supervised', 'num_workers': 8}\n",
      "train_unsupervised {'data_dir': 'unlabel_FA', 'batch_size': 8, 'shuffle': True, 'crop_size': 224, 'split': 'train_unsupervised', 'num_workers': 8}\n",
      "val_loader {'data_dir': 'FA', 'batch_size': 1, 'split': 'val', 'shuffle': False, 'num_workers': 4}\n",
      "test_loader {'data_dir': 'FA', 'batch_size': 1, 'split': 'test', 'shuffle': False, 'num_workers': 4}\n"
     ]
    }
   ],
   "source": [
    "#config\n",
    "batch_size = 8\n",
    "epochs = 80\n",
    "warm_up = 80\n",
    "labeled_examples = 515\n",
    "lr = 1e-2\n",
    "backbone = 101 #\" the resnet x {50, 101} layers\"\n",
    "semi_p_th = 0.6 # positive_threshold for semi-supervised loss\n",
    "semi_n_th = 0.0 # negative_threshold for semi-supervised loss\n",
    "unsup_weight = 1.5 # unsupervised weight for the semi-supervised loss\n",
    "\n",
    "config = json.load(open(\"configs/config_deeplab_v3+.json\"))\n",
    "\n",
    "config['train_supervised']['batch_size'] = batch_size\n",
    "config['train_unsupervised']['batch_size'] = batch_size\n",
    "config['model']['epochs'] = epochs\n",
    "config['model']['warm_up_epoch'] = warm_up\n",
    "config['n_labeled_examples'] = labeled_examples\n",
    "config['model']['resnet'] = backbone\n",
    "config['optimizer']['args']['lr'] = lr\n",
    "config['unsupervised_w'] = unsup_weight\n",
    "config['model']['data_h_w'] = [config['train_supervised']['crop_size'], config['train_supervised']['crop_size']]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "logger = logging.getLogger(\"PS-MT\")\n",
    "logger.propagate = False\n",
    "logger.warning(\"Training start, 总共 {} epochs\".format(str(config['model']['epochs'])))\n",
    "logger.critical(\"GPUs: {}\".format(device))\n",
    "logger.critical(\"DeeplabV3+ with ResNet {} backbone\".format(str(config['model']['resnet'])))\n",
    "logger.critical(\"Current Labeled Example: {}\".format(config['n_labeled_examples']))\n",
    "logger.critical(\"Learning rate: other {}, and head is the SAME [world]\".format(config['optimizer']['args']['lr']))\n",
    "\n",
    "logger.critical(\"Current batch: {} [world]\".format(int(config['train_unsupervised']['batch_size']) +\n",
    "                                                int(config['train_supervised']['batch_size'])) )\n",
    "\n",
    "logger.critical(\"Current unsupervised loss function: {}, with weight {} and length {}\".format(config['model']['un_loss'],\n",
    "                                                                                            config['unsupervised_w'],\n",
    "                                                                                            config['ramp_up']))\n",
    "print(\"\\nconfig json :\")\n",
    "for i in config:\n",
    "    print(i, config[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_supervised\n",
      "     data_dir : FA\n",
      "     batch_size : 8\n",
      "     shuffle : True\n",
      "     crop_size : 224\n",
      "     split : train_supervised\n",
      "     num_workers : 8\n",
      "     choose : All\n",
      "train_unsupervised\n",
      "     data_dir : unlabel_FA\n",
      "     batch_size : 8\n",
      "     shuffle : True\n",
      "     crop_size : 224\n",
      "     split : train_unsupervised\n",
      "     num_workers : 8\n",
      "     choose : All\n",
      "val_loader\n",
      "     data_dir : FA\n",
      "     batch_size : 1\n",
      "     split : val\n",
      "     shuffle : False\n",
      "     num_workers : 4\n",
      "     choose : All\n",
      "test_loader\n",
      "     data_dir : FA\n",
      "     batch_size : 1\n",
      "     split : test\n",
      "     shuffle : False\n",
      "     num_workers : 4\n",
      "     choose : All\n",
      "supervised_loader:  515\n",
      "unsupervised_loader:  5263\n",
      "val_loader:  162\n",
      "test_loader:  157\n"
     ]
    }
   ],
   "source": [
    "# DATA LOADERS\n",
    "from DataLoader.dataset_onlyFA import *\n",
    "choose_data = \"All\"\n",
    "\n",
    "config['train_supervised']['choose'] = choose_data\n",
    "config['train_unsupervised']['choose'] = choose_data\n",
    "config['val_loader']['choose'] = choose_data\n",
    "config['test_loader']['choose'] = choose_data\n",
    "\n",
    "print(\"train_supervised\")\n",
    "for i in config['train_supervised']:\n",
    "    print(\"    \",i, \":\", config['train_supervised'][i])\n",
    "print(\"train_unsupervised\")\n",
    "for i in config['train_unsupervised']:\n",
    "    print(\"    \", i, \":\", config['train_unsupervised'][i])\n",
    "print(\"val_loader\")\n",
    "for i in config['val_loader']:\n",
    "    print(\"    \", i, \":\", config['val_loader'][i])\n",
    "print(\"test_loader\")\n",
    "for i in config['test_loader']:\n",
    "    print(\"    \", i, \":\", config['test_loader'][i])\n",
    "\n",
    "supervised_set = BasicDataset(data_dir=config['train_supervised']['data_dir'], \n",
    "                                 choose=config['train_supervised']['choose'],\n",
    "                                 split=config['train_supervised']['split'])\n",
    "unsupervised_set = BasicDataset(data_dir=config['train_unsupervised']['data_dir'],\n",
    "                                   choose=config['train_unsupervised']['choose'],\n",
    "                                   split=config['train_unsupervised']['split'])\n",
    "val_set = BasicDataset(data_dir=config['val_loader']['data_dir'],\n",
    "                          choose=config['val_loader']['choose'],\n",
    "                          split=config['val_loader']['split'])\n",
    "\n",
    "test_set = BasicDataset(data_dir=config['test_loader']['data_dir'],\n",
    "                          choose=config['test_loader']['choose'],\n",
    "                          split=config['test_loader']['split'])\n",
    "\n",
    "print(\"supervised_loader: \",len(supervised_set))\n",
    "print(\"unsupervised_loader: \",len(unsupervised_set))\n",
    "print(\"val_loader: \",len(val_set))\n",
    "print(\"test_loader: \",len(test_set))\n",
    "\n",
    "\n",
    "supervised_loader = DataLoader(dataset=supervised_set, batch_size=config['train_supervised']['batch_size'],\n",
    "                               shuffle=config['train_supervised']['shuffle'], \n",
    "                               num_workers=config['train_supervised']['num_workers'])\n",
    "unsupervised_loader = DataLoader(dataset=unsupervised_set, batch_size=config['train_unsupervised']['batch_size'],\n",
    "                               shuffle=config['train_unsupervised']['shuffle'], \n",
    "                               num_workers=config['train_unsupervised']['num_workers'])\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=config['val_loader']['batch_size'],\n",
    "                               shuffle=config['val_loader']['shuffle'], \n",
    "                               num_workers=config['val_loader']['num_workers'])\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=config['test_loader']['batch_size'],\n",
    "                               shuffle=config['test_loader']['shuffle'], \n",
    "                               num_workers=config['test_loader']['num_workers'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameter: 60.75M\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "from Model.Deeplabv3_plus.psmt_model import *\n",
    "from Utils.ramps import *\n",
    "\n",
    "\n",
    "model_t1 = Teacher_Net(num_classes=2, config=config['model'])\n",
    "model_t1 = model_t1.to(device)\n",
    "\n",
    "optimizer_t1 = optim.SGD(model_t1.parameters(), \n",
    "                      lr=config['optimizer']['args']['lr'],\n",
    "                      momentum=config['optimizer']['args']['momentum'],\n",
    "                      weight_decay=config['optimizer']['args']['weight_decay'])\n",
    "\n",
    "total = sum([param.nelement() for param in model_t1.parameters()])\n",
    "print(\"Number of parameter: %.2fM\" % (total/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics, neighbors\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def information_index(outputs, targets):\n",
    "    eps = np.finfo(np.float64).eps\n",
    "    output = outputs.flatten()\n",
    "    target = targets.flatten()\n",
    "    TN, FP, FN, TP = confusion_matrix(target,output).ravel()\n",
    "\n",
    "    index_MIou =  ( TP / (TP + FP + FN + eps) + TN / (TN + FN + FP + eps) ) / 2\n",
    "    mean_iou = np.mean(index_MIou)\n",
    "    index_dice = 2*TP / (2*TP + FP + FN + eps)\n",
    "    mean_dice = np.mean(index_dice)\n",
    "\n",
    "    return mean_iou, mean_dice\n",
    "\n",
    "def count_index(pre, tar):\n",
    "        path_pre = pre\n",
    "        path_target = tar\n",
    "        dirs = os.listdir(path_pre)\n",
    "        # print(len(dirs))\n",
    "        con_mIOU = 0\n",
    "        con_mdice = 0\n",
    "        for imgs in dirs:\n",
    "            pre_path = path_pre + '/' + str(imgs)\n",
    "            target_path = path_target + '/' + str(imgs)\n",
    "\n",
    "            target = cv2.imread(target_path, cv2.IMREAD_GRAYSCALE)\n",
    "            _, tar = cv2.threshold(target, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            predict = cv2.imread(pre_path, cv2.IMREAD_GRAYSCALE)\n",
    "            _, pre = cv2.threshold(predict, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            tIOU, tdice = information_index(pre,tar)\n",
    "            con_mIOU += tIOU\n",
    "            con_mdice += tdice\n",
    "        val_mIoU = con_mIOU/len(dirs)\n",
    "        val_mDice = con_mdice/len(dirs)\n",
    "        \n",
    "        return val_mIoU, val_mDice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medpy import metric\n",
    "def calculate_metric_percase(pred, gt):\n",
    "    pred[pred > 0] = 1\n",
    "    gt[gt > 0] = 1\n",
    "    if pred.sum() > 0:\n",
    "        dice = metric.binary.dc(pred, gt)\n",
    "        hd95 = metric.binary.hd95(pred, gt)\n",
    "        return dice, hd95\n",
    "    else:\n",
    "        return 0, 0\n",
    "def test_single_volume(label, output, classes=2):\n",
    "    label = torch.clamp(label, 0, 1)\n",
    "    label = label.squeeze(0).cpu().detach().numpy()\n",
    "    output = output.cpu().detach().numpy()\n",
    "    metric_list = []\n",
    "    for i in range(1, classes):\n",
    "        metric_list.append(calculate_metric_percase(\n",
    "            output == i, label == i))\n",
    "    \n",
    "    return metric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:02<00:00, 61.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_models valiation : HD95 = 48.9310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# val HD\n",
    "\n",
    "PRED_MODEL_t1 = './saved_models/deeplabV3/original_epoch_5_dsc_0.3550_best_t1.pth'\n",
    "\n",
    "model_t1.load_state_dict(torch.load(PRED_MODEL_t1, map_location=device))\n",
    "\n",
    "folder_name = None\n",
    "folder_name = os.path.join(\"see_image\")\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "metric_list = 0.0\n",
    "model_t1.eval()\n",
    "for batch in tqdm(val_loader):\n",
    "    image_val, label, id_val = batch\n",
    "    image_val, label, id_val = image_val.to(device), label.to(device), id_val\n",
    "\n",
    "    H, W = label.size(1), label.size(2)\n",
    "    up_sizes = (ceil(H / 8) * 8, ceil(W / 8) * 8)\n",
    "\n",
    "    for i in range(0, int(label.size(0))):\n",
    "        folder_test = os.path.join(folder_name, \"backbone_val_target\")\n",
    "        os.makedirs(folder_test, exist_ok=True)\n",
    "        image = Image.fromarray(np.uint8(label[i].detach().cpu().numpy()))\n",
    "        image.save(os.path.join(folder_test, str(id_val[i]) + \".png\"))\n",
    "\n",
    "    data = torch.nn.functional.interpolate(image_val, size=(up_sizes[0], up_sizes[1]),\n",
    "                                            mode='bilinear', align_corners=True)\n",
    "    loss_t1, outputs = model_t1(x_FA=data, x_ICG=data, target_l=label,\n",
    "                                warm_up=True,mix_up=False)\n",
    "    output = outputs[\"sup_pred\"]\n",
    "\n",
    "    for i in range(0, int(output.size(0))):\n",
    "        folder_val_prob = os.path.join(folder_name, \"backbone_val_prob\")\n",
    "        os.makedirs(folder_val_prob, exist_ok=True)\n",
    "        image_prob = output[i].squeeze().detach()\n",
    "        image_prob = torch.argmax(image_prob, dim=0).cpu().numpy()\n",
    "        image_prob = Image.fromarray((image_prob * 255).astype(np.uint8))\n",
    "        image_prob.save(os.path.join(folder_val_prob, str(id_val[i]) + \".png\"))\n",
    "    # print(output.shape)\n",
    "    # print(label.shape)\n",
    "    out = torch.argmax(torch.softmax(output, dim=1), dim=1).squeeze(0)\n",
    "    # print(out.shape)\n",
    "    metric_i = test_single_volume(label, out, classes=2)\n",
    "    # print(metric_i)\n",
    "    metric_list += np.array(metric_i)\n",
    "metric_list = metric_list / len(val_set)\n",
    "# index_mDice = np.mean(metric_list, axis=0)[0]\n",
    "index_mean_hd95 = np.mean(metric_list, axis=0)[1]\n",
    "\n",
    "\n",
    "# show the best HD\n",
    "print(\"original_models valiation : \" + f'HD95 = {index_mean_hd95:.4f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSC = 0.3339375175277995, HD95 = 51.002782850749405\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# PRED_MODEL_t1 = os.path.join(model_path, f'original_epoch_{do_best_epoch}_dsc_{do_best_Dice:.4f}_best_t1.pth')\n",
    "\n",
    "\n",
    "folder_name = None\n",
    "folder_name = os.path.join(\"see_image\")\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# Test\n",
    "metric_list = 0.0\n",
    "model_t1.eval()\n",
    "for batch in tqdm(test_loader):\n",
    "    image_test, label, id_test = batch\n",
    "    image_test, label, id_test = image_test.to(device), label.to(device), id_test\n",
    "\n",
    "    H, W = label.size(1), label.size(2)\n",
    "    up_sizes = (ceil(H / 8) * 8, ceil(W / 8) * 8)\n",
    "\n",
    "    for i in range(0, int(label.size(0))):\n",
    "        folder_test = os.path.join(folder_name, \"backbone_test_target\")\n",
    "        os.makedirs(folder_test, exist_ok=True)\n",
    "        image = Image.fromarray(np.uint8(label[i].detach().cpu().numpy()))\n",
    "        image.save(os.path.join(folder_test, str(id_test[i]) + \".png\"))\n",
    "\n",
    "    data = torch.nn.functional.interpolate(image_test, size=(up_sizes[0], up_sizes[1]),\n",
    "                                               mode='bilinear', align_corners=True)\n",
    "    loss_t1, outputs = model_t1(x_FA=data, x_ICG=data, target_l=label,\n",
    "                                warm_up=True,mix_up=False)\n",
    "    output = outputs[\"sup_pred\"]\n",
    "\n",
    "    for i in range(0, int(output.size(0))):\n",
    "        folder_test_prob = os.path.join(folder_name, \"backbone_test_prob\")\n",
    "        os.makedirs(folder_test_prob, exist_ok=True)\n",
    "        image_prob = output[i].squeeze().detach()\n",
    "        image_prob = torch.argmax(image_prob, dim=0).cpu().numpy()\n",
    "        image_prob = Image.fromarray((image_prob * 255).astype(np.uint8))\n",
    "        image_prob.save(os.path.join(folder_test_prob, str(id_test[i]) + \".png\"))\n",
    "\n",
    "    out = torch.argmax(torch.softmax(output, dim=1), dim=1).squeeze(0)\n",
    "    metric_i = test_single_volume(label, out, classes=2)\n",
    "    metric_list += np.array(metric_i)\n",
    "metric_list = metric_list / len(test_set)\n",
    "\n",
    "# performance = np.mean(metric_list, axis=0)[0]\n",
    "\n",
    "mean_hd95 = np.mean(metric_list, axis=0)[1]\n",
    "\n",
    "# show epoch mIoU, mDice\n",
    "index_mIoU, index_mDice = count_index(folder_test_prob, folder_test)\n",
    "\n",
    "\n",
    "print(f'DSC = {index_mDice}, HD95 = {mean_hd95}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps-mt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
